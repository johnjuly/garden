## **内存管理阶段与物理内存分配**

### **内存管理阶段划分**

- 早期阶段：指出，早期可用内存数量远大于单个应用程序消耗的内存量，此阶段主要解决如何高效分配大片可用内存给各程序的问题。为提高内存利用率，有 best fit、worst fit、Buddy system 等多种分配方案，需注意算法效率和内存连续性这两个关键因素。

- 后期阶段：随着高级编程语言和软件工程理论的出现，应用程序规模增大，物理内存无法满足需求。此时，覆盖技术曾被提出，但因掌握难度大、难以形成大规模开发者队伍而被淘汰。

### **物理内存管理要点**

- Swap 技术：Swap 技术可将临时不运行的进程踢出去，使其进入挂起状态，从而节省物理内存。这一技术实现了进程调度模型与物理内存分配状态的联动。

- 内存连续性：内存连续性是重要资源，连续的内存块比分散的内存块更有价值，因为分散的内存块整合需要额外手段。

##  **虚拟内存与页表机制**

###  **虚拟内存引入**

- 覆盖技术局限：覆盖技术虽能减少给程序员分配的内存，但因需要高级程序员掌控，难以大规模应用，最终被淘汰。

- MMU 与页表作用：为解决应用程序规模与物理内存的矛盾，引入了虚拟内存和 MMU（内存管理单元）。MMU 位于 CPU 和内存之间，可对内存地址进行偏转或翻折，将程序员请求的内存地址映射到实际可用的物理内存地址。

### **页表的构建与管理**

- 页的划分与地址转换：将内存划分为页，页是管理内存的最小单元，通常为 4096 字节。通过位操作将地址分为页号和页内偏移量，建立页号与物理内存中页框号的对应关系，存储在页表中。

- 多级页表的原理与应用：以 32 位计算机系统为例，因需要巨大的页表来描述地址空间，引入多级页表。多级页表是用时间换空间的过程，虽会使访存变慢，但可节省内存。如 80386 采用两级页表，每个页表项占 4 字节，每个分支节点为 4K，可存储 1024 项。

- 64 位计算机系统的页表：64 位计算机系统的页表项变为 8 字节，每个 4K 的页能放 512 项，需构建更深的树状页表结构。英特尔处理器通过寄存器标注有效地址线位数，个人计算机平台通常使能 36 位或 46 位，服务器领域起始为 40 位，后调整到 48 位。

##  **大页技术与性能优化**

### **大页技术的原理**

- 页的合并：随着计算机设计资源的增加，可将连续申请的 512 个 4K 页合并成一个 2M 的大页，直接由上一级分支节点指向其起始地址，省掉一级分支节点。

- 减少 TLB 消耗：大页技术可减少查页表的时间，提升 TLB（快表）的利用率。因为连续的 512 个页合并成大页后，在 TLB 中只需占一项，而不合并则需消耗 512 项。

### **大页技术的应用限制**
虽然理论上可进一步合并成 1G 的页，但缺页处理时读取 1G 数据的时间过长，几乎无人能忍受，所以 1G 大的页鲜有人用。

## **页面置换算法**

- **页面置换的必要性**：当程序员声称需要的页超过实际分配的物理内存时，如承诺 16 个页但只给 8 个页，若程序员用完 8 个页后继续访问其他页，就会出现缺页情况，需要进行页面置换。

### **页面置换算法分析**

- Optimal 算法：若能预测未来，选择最远使用的页进行置换可使缺页次数最少，但该算法无法实际实现，不过对写论文有参考价值，且可通过记录访存序列进行 Replay 优化。

- FIFO 算法：先进来的页先被置换，算法设计和硬件实现简单，但可能出现贝莱迪现象，即增加物理页框后缺页次数反而增加。

- LRU 算法：最近被访问过的页换出优先级最低，可通过维护一个栈来实现。该算法能克服贝莱迪现象，但硬件实现复杂，且部分程序不具备局部性，会影响其效果。

- LFU 算法：根据页面过去被访问的次数推断其未来被使用的可能性，通过计数器记录访问次数。但计数器位数有限，易出现溢出问题。

- 时钟置换算法：用一个比特记录页面是否被访问过，通过周期性运转的线程清空访问标记。缺页时，选择访问标记为 0 的页面进行置换。该算法可通过增加 dirty bit 进一步优化，考虑页面是否被写过，避免不必要的磁盘写入。

## **学习与工具使用建议**

- **大模型的应用**：鼓励学生善用大模型辅助学习，不过分纠结死记硬背内容，如查询处理器的最大虚拟地址空间等信息。但强调学生应将大模型作为工具，而不是依赖其完成作业，要注重自身能力的培养。

- **学科知识的关联**：强调操作系统、组成原理、体系结构等学科知识的关联，如页表的翻译过程涉及组成原理，操作系统负责维护页表；TLB 技术与 CACHE 技术相关。提醒学生在学习中建立综合认知，理解不同学科在计算机系统中的作用。